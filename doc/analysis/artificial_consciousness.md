#Artificial consciousness analysis. 

https://en.wikipedia.org/wiki/Artificial_consciousness

## Principles

### Bernard Baars

The functions of consciousness suggested by Bernard Baars are:

1. Definition and Context Setting, 
1. Adaptation and Learning, 
1. Editing, 
1. Flagging and Debugging, 
1. Recruiting and Control, 
1. Prioritizing and Access-Control, 
1. Decision-making or Executive Function, 
1. Analogy-forming Function, 
1. Metacognitive and Self-monitoring Function, 
1. Autoprogramming and Self-maintenance Function.

#### Lit 

1. Baars, Bernard (1988), A Cognitive Theory of Consciousness, Cambridge, MA: Cambridge University Press, ISBN 0-521-30133-5

### Igor Aleksander 

Igor Aleksander  suggested 12 principles for Artificial Consciousness (Aleksander 1995) and these are: 

1. The Brain is a State Machine, 
1. Inner Neuron Partitioning, 
1. Conscious and Unconscious States, 
1. Perceptual Learning and Memory, 
1. Prediction, 
1. The Awareness of Self, 
1. Representation of Meaning, 
1. Learning Utterances, 
1. Learning Language, 
1. Will, 
1. Instinct,
1. Emotion.

#### Lit

1. [Aleksander, Igor (1995), Artificial Neuroconsciousness: An Update, IWANN, archived from the original on 1997-03-02 BibTex Internet Archive](http://web.archive.org/web/19970302014628/http://www.ee.ic.ac.uk/research/neural/publications/iwann.html)

### Additional principles

1. Awareness
1. Learning
1. Anticipation
1. Subjective experience 

## Proposed Cognitive architectures

### Franklin's Intelligent Distribution Agent

Stan Franklin (1995, 2003) defines an autonomous agent as possessing functional consciousness when it is capable of several of the functions of consciousness as identified by Bernard Baars' [Global Workspace Theory](https://en.wikipedia.org/wiki/Global_Workspace_Theory) (Baars 1988, 1997).

#### Lit

1. [Baars, Bernard (1988), A Cognitive Theory of Consciousness, Cambridge, MA: Cambridge University Press, ISBN 0-521-30133-5](http://cogweb.ucla.edu/Abstracts/Baars_88.html)
1. [Baars, Bernard (1997), In the Theater of Consciousness, New York, NY: Oxford University Press, ISBN 0-19-510265-7](http://bernardbaars.pbworks.com/f/Baars%20Theater%20book%20Ch%201-2.pdf)
1. Franklin, Stan (1995), Artificial Minds, Boston, MA: MIT Press, ISBN 0-262-06178-3
1. [Franklin, Stan (2003), "IDA: A Conscious Artefact", in Holland, Owen, Machine Consciousness, Exeter, UK: Imprint Academic](http://www.theassc.org/files/assc/IDA-ConsciousArtifact.pdf)

### Ron Sun's cognitive architecture CLARION

[CLARION](https://en.wikipedia.org/wiki/CLARION_(cognitive_architecture) ) posits a two-level representation that explains the distinction between conscious and unconscious mental processes.

CLARION has been successful in accounting for a variety of psychological data. A number of well-known skill learning tasks have been simulated using CLARION that span the spectrum ranging from simple reactive skills to complex cognitive skills. The tasks include serial reaction time (SRT) tasks, artificial grammar learning (AGL) tasks, process control (PC) tasks, the categorical inference (CI) task, the alphabetical arithmetic (AA) task, and the Tower of Hanoi (TOH) task (Sun 2002). Among them, SRT, AGL, and PC are typical implicit learning tasks, very much relevant to the issue of consciousness as they operationalized the notion of consciousness in the context of psychological experiments.

#### Lit

1. [Sun, Ron (December 1999), "Accounting for the computational basis of consciousness: A connectionist approach", Consciousness and Cognition 8 (4): 529–565, doi:10.1006/ccog.1999.0405, PMID 10600249](http://ac.els-cdn.com/S1053810099904051/1-s2.0-S1053810099904051-main.pdf?_tid=f51ba300-5020-11e3-a7dd-00000aab0f6b&acdnat=1384759003_2859273c25811d4f56b21f9a38eb3ba7)

### Ben Goertzel's OpenCog

Ben Goertzel is pursuing an embodied AGI through the open-source OpenCog project. Current code includes embodied virtual pets capable of learning simple English-language commands, as well as integration with real-world robotics, being done at the robotics lab of Hugo de Garis at Xiamen University.

### Haikonen's cognitive architecture

Pentti Haikonen (2003) considers classical rule-based computing inadequate for achieving AC: "the brain is definitely not a computer. Thinking is not an execution of programmed strings of commands. The brain is not a numerical calculator either. We do not think by numbers." Rather than trying to achieve mind and consciousness by identifying and implementing their underlying computational rules, Haikonen proposes "a special cognitive architecture to reproduce the processes of perception, inner imagery, inner speech, pain, pleasure, emotions and the cognitive functions behind these. 

Haikonen is not alone in this process view of consciousness, or the view that AC will spontaneously emerge in autonomous agents that have a suitable neuro-inspired architecture of complexity; these are shared by many, e.g. Freeman (1999) and Cotterill (2003). A low-complexity implementation of the architecture proposed by Haikonen (2003) was reportedly not capable of AC, but did exhibit emotions as expected. See Doan (2009) for a comprehensive introduction to Haikonen's cognitive architecture. An updated account of Haikonen's architecture, along with a summary of his philosophical views, is given in Haikonen (2012).

#### Lit

1. Freeman, Walter (1999), How Brains make up their Minds, London, UK: Phoenix, ISBN 0-231-12008-7
1. [Haikonen, Pentti (2003), The Cognitive Approach to Conscious Machines, Exeter, UK: Imprint Academic, ISBN 0-907845-42-8](http://www.theassc.org/files/assc/2604.pdf)
1. Cotterill, Rodney (2003), "Cyberchild: a Simulation Test-Bed for Consciousness Studies", in Holland, Owen, Machine Consciousness, Exeter, UK: ImprintAcademic
1. [Doan, Trung (2009), Pentti Haikonen's architecture for conscious machines](http://www.conscious-robots.com/en/conscious-machines/theories-of-consciousness/pentti-haikonens-architecture-for-conscious-mac.html)
1. Haikonen, Pentti (2012), Consciousness and Robot Sentience, Singapore: World Scientific, ISBN 978-981-4407-15-1

### Shanahan's cognitive architecture

Murray Shanahan describes a cognitive architecture that combines Baars's idea of a global workspace with a mechansim for internal simulation ("imagination") (Shanahan 2006). For discussions of Shanahan's architecture, see (Gamez 2008) and (Reggia 2013) and Chapter 20 of (Haikonen 2012).

#### Lit

1. [Shanahan, Murray (2006), "A cognitive architecture that combines internal simulation with a global workspace", Consciousness and Cognition 15: 443–449, doi:10.1016/j.concog.2005.11.005](http://dx.doi.org/10.1016%2Fj.concog.2005.11.005), [pdf](http://ac.els-cdn.com/S1053810005001510/1-s2.0-S1053810005001510-main.pdf?_tid=0bd34166-5026-11e3-8d04-00000aacb35e&acdnat=1384761189_228c216af1263b25f4b84e722947ab50)
1. [Gamez, David (2008), "Progress in machine consciousness", Consciousness and Cognition 17: 887–910, doi:10.1016/j.concog.2007.04.005](http://www.sciencedirect.com/science/article/pii/S1053810007000347)
1. [Reggia, James (2013), "The rise of machine consciousness: Studying consciousness with computational models", Neural Networks 44: 112–131, doi:10.1016/j.neunet.2013.03.011](http://www.sciencedirect.com/science/article/pii/S0893608013000968)

### Takeno's self-awareness research

Self-awareness in robots is being investigated by Junichi Takeno [2] at Meiji University in Japan. Takeno is asserting that he has developed a robot capable of discriminating between a self-image in a mirror and any other having an identical image to it [3][4], and this claim has already been reviewed (Takeno, Inaba & Suzuki 2005). Takeno asserts that he first contrived the computational module called a MoNAD, which has a self-aware function, and he then constructed the artificial consciousness system by formulating the relationships between emotions, feelings and reason by connecting the modules in a hierarchy (Igarashi, Takeno 2007). 
                                                                                               
#### Lit

http://www.s2is.org/Issues/v1/n4/papers/paper4.pdf


### Aleksander's impossible mind

Igor Aleksander, emeritus professor of Neural Systems Engineering at Imperial College, has extensively researched artificial neural networks and claims in his book Impossible Minds: My neurons, My Consciousness that the principles for creating a conscious machine already exist but that it would take forty years to train such a machine to understand language. Whether this is true remains to be demonstrated and the basic principle stated in Impossible minds—that the brain is a neural state machine—is open to doubt.

#### Lit

1. Aleksander I (1996) Impossible Minds: My neurons, My Consciousness, Imperial College Press ISBN 1-86094-036-6
1.  Wilson RJ (1998) review of Impossible Minds. Journal of Consciousness Studies 5(1), 115-6.